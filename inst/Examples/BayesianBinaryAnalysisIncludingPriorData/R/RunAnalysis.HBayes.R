#  Last Modified Date: 11/06/2025
#' @name BayesianBinaryAnalysisIncludingPriorData
#' @param SimData Data frame with subject data generated in current simulation with one row per patient. 
#'        It will have headers indicating the names of the columns. These names will be same as those used in 
#'        Data Generation. User should access the variables using headers, for example, SimData$ArrivalTime, 
#'        and not order. Optional outputs generated by Data Generation will also be available as columns of 
#'        this data frame. For analysis the most relevant variables are:
#'        \describe
#'        {
#'          \item{ArrivalTime}{A numeric value with the time the patient arrived in the trial}
#'          \item{TreatmentID}{An integer value where 0 indicates control treatment and 1 experimental treatment.}
#'          \item{Response}{An integer value where 1 indicates response and 0 indicates no response.}
#'          \item{CensorIndOrg}{An integer value indicating whether the subject was censored or not.}
#'        }
#' @param DesignParam R List which consists of Design and Simulation Parameters which user
#'      may need to compute test statistic and perform test. User should access the variables
#'      using names for e.g., DesignParam$Alpha and not order. Them items are as follows:
#'      \describe{
#'          \item{SampleSize}{Sample size of the trial}
#'          \item{Alpha}{Type I Error}
#'          \item{TestType}{Values are One side: 0; Two Sided: 1, Two Sided, Asymmetric: 2}
#'          \item{TailType}{Values are Left Tailed: 0, Right Tailed: 1}
#'          \item{LowerAlpha}{Lower Type I error. Present for Left Tailed and Two Sided Asymmetric Tests }
#'          \item{UpperAlpha}{Upper Type I error. Present for Right Tailed and Two Sided Asymmetric Tests }
#'          \item{MaxCompleters}{Maximum Number of Completers}
#'          \item{FollowUpType}{For survival tests, Follow Up Type.  Possible values are: Until End ofS Study: 0, For fixed period: 1}
#'          \item{AllocInfo}{Vector of ratios of treatment sample sizes to control sample size. Length = Number of treatment arms. }
#'          \item{CriticalPoint}{Critical Value. Present in Fixed Sample designs only }
#'          \item{UpperCriticalPoint}{Upper Critical Value. Present in Right Tail Fixed Sample designs only }
#'          \item{LowerCriticalPoint}{Lower Critical Value. Present in Left Tail Fixed Sample designs only }
#'          \item{RespLag}{Follow up duration}
#'          \item{TrtEffNull}{Treatment Effect under Null on natural scale. Applicable for Non-inferiority trials.}
#'      
#'      }
#' @param LookInfo List Input Parameters related to multiple looks which user may need to compute test statistic 
#'                 and perform test. User should access the variables using names, 
#'                 for example LookInfo$NumLooks and not order. Other important variables in group sequential designs are: 
#'                 \describe{
#'                      \item{NumLooks}{An integer value with the number of looks in the study}
#'                      \item{CurrLookIndex}{An integer value with the current index look, starting from 1}
#'                      \item{CumCompleters}{Cumulative number of completer for all non time-to-event studies.}
#'                      \item{InfoFrac}{Information fraction}
#'                      \item{CumAlpha}{Cumulative alpha spent. Present in one sided tests only }
#'                      \item{CumAlphaUpper}{Upper cum. alpha spent. Present in right tailed and two sided tests only }
#'                      \item{CumAlphaLower}{Lower cum. alpha spent. Present in left tailed and two sided tests only }
#'                      \item{EffBdryScale}{Efficacy boundary scale.  Possible vaues are: Z Scale: 0, p-Value Scale: 1}
#'                      \item{EffBdry}{Vector of efficacy bondaries. Present in one sided tests only }
#'                      \item{EffBdryUpper}{Vector of upper efficacy bondaries. Present in right tailed and two sided tests only }
#'                      \item{EffBdryLower}{Vector of lower efficacy boundary. Present in left tailed and two sided tests only }
#'                      \item{FutBdryScale}{Futility boundary scale. Possible value are: Z Scale: 0, p-Value Scale: 1, Delta Scale: 2, Conditional Power Scale: 3}
#'                      \item{FutBdry}{Vector of futility bondaries. Present in one sided tests only }
#'                      \item{FutBdryUpper}{Vector of upper futility boundaries. Present in left tailed and two sided tests only }
#'                      \item{FutBdryLower}{Vector of lower futility boundaries. Present in right tailed and two sided tests only }
#'                 }
#' @param UserParam User can pass custom scalar variables defined by users as a member of this list. 
#'                  User should access the variables using names, for example UserParam$Var1 and not order. 
#'                  These variables can be of the following types: Integer, Numeric, or Character
#' @return The function must return a list in the return statement of the function. The information below lists 
#'             elements of the list, if the element is required or optional and a description of the return values if needed.
#'             \describe{
#'                  \item{Decision}{Optional value. Integer Value with the following meaning:
#'                                  \describe{
#'                                    \item{Decision = 0}{when No boundary, futility or efficacy is crossed}
#'                                    \item{Decision = 1}{when the Lower Efficacy Boundary Crossed}
#'                                    \item{Decision = 2}{when the Upper Efficacy Boundary Crossed}
#'                                    \item{Decision = 3}{when the Futility Boundary Crossed}
#'                                    \item{Decision = 4}{when the Equivalence Boundary Crossed}
#'                                    } 
#'                                    }
#'                  \item{TestStat}{Numeric value. Required if Decision is not returned}
#'                  \item{Delta}{Numeric value. Required if Decision is not returned AND Futility Boundary scale is either Delta or CP.}
#'                  \item{CtrlCompleters}{Integer value. Required if Decision is not returned and Futility Boundary scale is CP.}
#'                  \item{TrmtCompleters }{Integer value. Required if Decision is not returned and Futility Boundary scale is CP.}
#'                  \item{CtrlPi}{Numeric value. Required if Decision is not returned and Futility Boundary scale is CP.}
#'                  \item{ErrorCode}{Optional integer value \describe{ 
#'                                     \item{ErrorCode = 0}{No Error}
#'                                     \item{ErrorCode > 0}{Nonfatal error, current simulation is aborted but the next simulations will run}
#'                                     \item{ErrorCode < 0}{Fatal error, no further simulation will be attempted}
#'                                     }
#'                                     }
#'    


# ***********************************************************************************************************
# IMPORTANT NOTE - IN THIS VERSION I TRIED TO UPLOAD THE PriorStudies.Rds DATASET TO EAST HORIZON 
# BUT I KEPT RUNNING INTO ISSUES WHERE WITH A LARGE NUMBER OF MODELS THE SIMUAITONS WOULD CRASH.  
# THIS HAS BEEN REPORTED BUT AS A WORK AROUND IN THE v2 OF THE FILE I HARD CODE THE PRIOR DATA
# ***********************************************************************************************************

RunAnalysis.HBayes <- function(SimData, DesignParam, LookInfo = NULL, UserParam = NULL) {
    # Initialize variables
    
    library( CyneRgy )
    library( rjags )
    library( coda )
    
    nError <- 0
    nDecision <- 0
    dTestStatistic <- 0
    
    # Step 1: Determine the current look and number of patients in analysis
    if (!is.null(LookInfo)) {
        nLookIndex <- LookInfo$CurrLookIndex
        nQtyOfLooks <- LookInfo$NumLooks
        nQtyOfPatsInAnalysis <- LookInfo$CumCompleters[nLookIndex]
    } else {
        nLookIndex <- 1
        nQtyOfLooks <- 1
        nQtyOfPatsInAnalysis <- nrow(SimData)
    }
    
    nTry <- 0
    while( !exists( "dfPriorStudies") && nTry < 10 )
    {
        tryCatch({       
            print(paste0( "Try ", nTry ))
            dfPriorStudies <<- readRDS(  "Inputs/PriorStudies.Rds")
            }, error=function(e){
                nTry <<- nTry + 1
                Sys.sleep( runif( 1, 1,5) )
            })
    }
    
    # Step 2: Extract patient outcomes and treatment assignments
    vPatientOutcome <- SimData$Response[1:nQtyOfPatsInAnalysis]
    vPatientTreatment <- SimData$TreatmentID[1:nQtyOfPatsInAnalysis]
    
    # Separate outcomes by treatment group
    vOutcomesCtrl <- vPatientOutcome[vPatientTreatment == 0]
    vOutcomesExp <- vPatientOutcome[vPatientTreatment == 1]
    
    # Step 3: Perform Bayesian analysis for posterior probability
    lPosterior <- ProbExpGreaterCtrlBeta(
        vOutcomesCtrl, vOutcomesExp,
        UserParam$dAlphaCtrl, UserParam$dBetaCtrl,
        UserParam$dAlphaExp, UserParam$dBetaExp
    )
    
    # Check efficacy boundary
    strDecision <- "INVALID"
    dPredProb   <- NA
    if( nLookIndex < nQtyOfLooks )
    {
        # Interim analysis
        if (lPosterior$dPostProb > UserParam$PU) 
        {
            strDecision <- CyneRgy::GetDecisionString( LookInfo, nLookIndex, nQtyOfLooks, bIAEfficacyCondition = TRUE )
            nDecision   <- CyneRgy::GetDecision( strDecision, DesignParam, LookInfo  )  # Stop for success
        } 
        else 
        {
            nFinalNExp <- DesignParam$MaxCompleters *( DesignParam$AllocInfo[1]/( DesignParam$AllocInfo[1]+ 1) )
            nFinalNCtrl  <-  DesignParam$MaxCompleters - nFinalNExp
            # Step 4: Compute Bayesian predictive probability for futility
            if( UserParam$FutilityCheck == 0 )
            {
                lPredictive <- list(predictiveProbabilityS= 1) # Skip futility check
            }
            else
            {
                lPredictive <- ComputeBayesianPredictiveProbabilityWithHierBayesianAnalysis(dfPriorStudies,
                    vOutcomesCtrl, vOutcomesExp,
                    UserParam$dAlphaCtrl, UserParam$dBetaCtrl,
                    UserParam$dAlphaExp, UserParam$dBetaExp,
                    nFinalNCtrl,
                    nFinalNExp,
                    UserParam$nSimulations, UserParam$PUFinal )
            }
            
            # Check futility boundary
            dPredProb <- lPredictive$predictiveProbabilityS
            if (dPredProb < UserParam$PL) {
                # Stop for futility
                strDecision <- CyneRgy::GetDecisionString( LookInfo, nLookIndex, nQtyOfLooks, bIAFutilityCondition = TRUE )
                nDecision   <- CyneRgy::GetDecision( strDecision, DesignParam, LookInfo  )  # Stop for success
                
            }
            else
            {
                strDecision <- CyneRgy::GetDecisionString( LookInfo, nLookIndex, nQtyOfLooks, bIAFutilityCondition = FALSE )
            }
        }
    }
    else
    {
        if (lPosterior$dPostProb > UserParam$PUFinal) 
        {
            #Success at FA
            strDecision <- CyneRgy::GetDecisionString( LookInfo, nLookIndex, nQtyOfLooks, bFAEfficacyCondition = TRUE )
            nDecision   <- CyneRgy::GetDecision( strDecision, DesignParam, LookInfo  )  # Success at FA
        }
        else
        {
            #Futility at FA
            strDecision <- CyneRgy::GetDecisionString( LookInfo, nLookIndex, nQtyOfLooks, bFAFutilityCondition = TRUE )
            nDecision   <- CyneRgy::GetDecision( strDecision, DesignParam, LookInfo  )  # Success at FA
        }
    }
    
    # Return results
    return(list( strDecision = strDecision,
                 dPredProb = as.double( dPredProb ),
        TestStat = as.double(lPosterior$dPostProb),
        Decision = as.integer(nDecision),
        ErrorCode = as.integer(nError)
    ))
}

# Function to compute posterior probability using Beta-Binomial model
ProbExpGreaterCtrlBeta <- function(vOutcomesCtrl, vOutcomesExp, dAlphaCtrl, dBetaCtrl, dAlphaExp, dBetaExp) {
    # Update posterior parameters for control group
    dAlphaCtrl <- dAlphaCtrl + sum(vOutcomesCtrl)
    dBetaCtrl <- dBetaCtrl + length(vOutcomesCtrl) - sum(vOutcomesCtrl)
    
    # Update posterior parameters for experimental group
    dAlphaExp <- dAlphaExp + sum(vOutcomesExp)
    dBetaExp <- dBetaExp + length(vOutcomesExp) - sum(vOutcomesExp)
    
    # Sample posterior distributions
    vPiCtrl <- rbeta(10000, dAlphaCtrl, dBetaCtrl)
    vPiExp <- rbeta(10000, dAlphaExp, dBetaExp)
    
    # Compute posterior probability
    dPostProb <- mean(vPiExp > vPiCtrl)
    
    return(list(dPostProb = dPostProb))
}

# Function to compute Bayesian predictive probability of success
ComputeBayesianPredictiveProbabilityWithHierBayesianAnalysis <- function( dfPriorStudies,
        dataCtrl, dataExp, priorAlphaCtrl, priorBetaCtrl, priorAlphaExp, priorBetaExp,
        nFinalCtrl, nFinalExp, nSimulations, finalBoundary
) {
    # Update posterior parameters based on observed data
    nYCtrl <-  sum(dataCtrl)
    nNCtrl <- length(dataCtrl) 
    
    posteriorAlphaExp <- priorAlphaExp + sum(dataExp)
    posteriorBetaExp <- priorBetaExp + length(dataExp) - sum(dataExp)
    
    # Initialize counter for successful trials
    successfulTrials <- 0
    
    vY <- c( nYCtrl, dfPriorStudies$Y )
    vN <- c( nNCtrl, dfPriorStudies$N )
    
    lFit <- RunHierBinomJAGS( vY = vY,vN = vN, nIter = nSimulations)
    vPostRateCtrl <- lFit$vCurrentStudy
    
    # Simulate remaining trials and compute predictive probability
    for (i in 1:nSimulations) {
        # Sample response rates from posterior distributions
        posteriorRateCtrl <- vPostRateCtrl[ i ]
        posteriorRateExp <- rbeta(1, posteriorAlphaExp, posteriorBetaExp)
        
        # Simulate outcomes for remaining patients
        remainingCtrl <- rbinom(nFinalCtrl - length(dataCtrl), 1, posteriorRateCtrl)
        remainingExp <- rbinom(nFinalExp - length(dataExp), 1, posteriorRateExp)
        
        # Combine observed and simulated data
        combinedCtrl <- c(dataCtrl, remainingCtrl)
        combinedExp <- c(dataExp, remainingExp)
        
        # Perform Bayesian analysis on combined data
        lResult <- ProbExpGreaterCtrlBeta(
            combinedCtrl, combinedExp,
            priorAlphaCtrl, priorBetaCtrl,
            priorAlphaExp, priorBetaExp
        )
        
        # Check if trial meets success criteria
        if (lResult$dPostProb > finalBoundary) {
            successfulTrials <- successfulTrials + 1
        }
    }
    
    # Compute predictive probability of success
    predictiveProbabilityS <- successfulTrials / nSimulations
    
    return(list(predictiveProbabilityS = predictiveProbabilityS))
}



RunHierBinomJAGS <- function( vY, vN, nIter = 1000, nBurn = 3000, nChains =2, nThin = 2, nAdapt = 1000 ) {
    # vY: integer vector of responders per study
    # vN: integer vector of totals per study (same length as vY)
    # Returns: list with MCMC samples and a summary data frame
    
    if ( length( vY ) != length( vN ) ) {
        stop( "vY and vN must have equal length" )
    }
    if ( any( vY < 0 ) || any( vN <= 0 ) || any( vY > vN ) ) {
        stop( "Counts must satisfy 0 <= vY[i] <= vN[i], with vN[i] > 0" )
    }
    
    #set.seed( nSeed )
    suppressPackageStartupMessages( library( rjags ) )
    suppressPackageStartupMessages( library( coda ) )
    
    nStud <- length( vY )
    
    strModel <- "
  model {
    for (i in 1:Nstud) {
      y[i] ~ dbin(p[i], n[i])
      logit(p[i]) <- mu + u[i]
      u[i] ~ dnorm(0, prec)
    }
    mu  ~ dnorm(0, 1.0E-4) # prior mean 0.2
    tau ~ dunif(0, 5)
    tau2 <- tau * tau
    prec <- 1 / tau2
    pOverallLogitMean <- ilogit(mu)
  }"
    
    lData <- list(
        Nstud = nStud,
        y = as.integer( vY ),
        n = as.integer( vN )
    )
    
    MakeInits <- function() {
        # Initialize around empirical logit with small jitter
        dMuStart <- qlogis( ( sum( vY ) + 0.5 ) / ( sum( vN ) + 1.0 ) )
        lInit <- list(
            mu = rnorm( 1, dMuStart, 0.5 ),
            tau = runif( 1, 0.1, 1.0 ),
            u = rnorm( nStud, 0, 0.2 )
        )
        return( lInit )
    }
    lInits <- replicate( nChains, MakeInits(), simplify = FALSE )
    
    mJags <- jags.model(
        file = textConnection( strModel ),
        data = lData,
        inits = lInits,
        n.chains = nChains,
        n.adapt = nAdapt
    )
    
    update( mJags, n.iter = nBurn )
    
    vParams <- c( "mu", "tau", "pOverallLogitMean", "p" )
    mcmc <- coda.samples(
        model = mJags,
        variable.names = vParams,
        n.iter = nIter,
        thin = nThin
    )
    smry <- summary( mcmc )
    dfQuant <- as.data.frame( smry$quantiles )
    dfStats <- as.data.frame( smry$statistics )
    dfOut <- cbind( Parameter = rownames( dfStats ), dfStats, dfQuant )
    rownames( dfOut ) <- NULL
    
    strCurrentStudy <- paste0( "p[", 1, "]" )
    vCurrentStudy <- as.numeric(
        do.call(
            rbind,
            lapply( mcmc, function( x ) x[ , strCurrentStudy, drop = TRUE ] )
        )
    )
    
    lRet <- list(
        samples = mcmc,
        summary = dfOut,
        vCurrentStudy = vCurrentStudy
    )
    return( lRet )
}



